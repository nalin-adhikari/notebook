{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1A2h_bRuwEck4whbto2C5H64KgG-g75W-",
      "authorship_tag": "ABX9TyMPO6SN2/H+YRRpESLKRscN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalin-adhikari/notebook/blob/master/Regression/Combined%20Cycle%20Power%20Plant/Regression-Combined_Cycle_Power_Plant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regression | Combined Cycle Power Plant"
      ],
      "metadata": {
        "id": "ANf2OmTVy-P7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "lOqC8s8LzBfn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FeLpt1RmzSRC",
        "outputId": "dba4e21f-f5e3-46af-e37a-e5a48ea8c0fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.19.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 1 - Data Preprocessing"
      ],
      "metadata": {
        "id": "uf2OOl5izebD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing the dataset"
      ],
      "metadata": {
        "id": "RIlNg_CIztFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel('data.xlsx')\n",
        "# Selects all rows (:) and all columns except the very last one (:-1). The .values then converts this selected data into a NumPy array\n",
        "X = dataset.iloc[:, :-1].values\n",
        "# Selects all rows (:) but only the last column (-1) from the dataset. This is also converted into a NumPy array using .values, and this array is the target variable (or dependent variable) y.\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "VG71NM03zoeX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Splitting the dataset into the Training set and Test set"
      ],
      "metadata": {
        "id": "pJIrNwdm0Ili"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# X and y are features and target variable (the data we want to split).\n",
        "# test_size = 0.2 means that 20% of our data will be used for the 'test set', and the remaining 80% will be for the 'training set'.\n",
        "# random_state = 0 is like setting a specific seed for shuffling the data. It ensures that every time we run this code, the split is exactly the same, which is good for reproducible results!\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "gnhKnx-G0Byy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 2 - Building the ANN"
      ],
      "metadata": {
        "id": "4FemCx7t0Ryd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initializing the ANN"
      ],
      "metadata": {
        "id": "Mo4eb07H0WhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "QKy4nm150Q_E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Adding the input layer and the first hidden layer"
      ],
      "metadata": {
        "id": "RnySbfPO0d2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ann.add(...) means we are adding a new layer to our neural network, which was initialized as Sequential().\n",
        "# tf.keras.layers.Dense(...) creates a 'Dense' layer, which is a standard type of layer in neural networks where every neuron in this layer is connected to every neuron in the previous layer. Think of it as a fully connected part of the network.\n",
        "# units=6 specifies that this particular hidden layer will have 6 neurons. The number of neurons in a hidden layer is a hyperparameter that we can tune.\n",
        "# activation='relu' sets the activation function for these 6 neurons to 'Rectified Linear Unit' (ReLU). The activation function decides whether a neuron should be activated or not, helping the network learn complex patterns. ReLU is a very common choice for hidden layers because it's computationally efficient and helps with training deeper networks.\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "wqd6FqlX0aig"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Adding the second hidden layer"
      ],
      "metadata": {
        "id": "oGNWTVJO0k6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "Rn1QOmTG0kk2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Adding the output layer"
      ],
      "metadata": {
        "id": "MHwfm8p70qcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.layers.Dense(...) again creates a 'Dense' layer, just like the hidden layers.\n",
        "# units=1 specifies that this layer will have only one neuron. In regression problems, where we are trying to predict a single continuous value (like the power output in this case), the output layer typically has one neuron.\n",
        "# We have not specified any activation here. When no activation function is explicitly set for the output layer in a regression problem, it defaults to a 'linear' activation. This means the neuron's output is directly its input, allowing it to predict any real-valued number, which is suitable for regression.\n",
        "ann.add(tf.keras.layers.Dense(units=1))"
      ],
      "metadata": {
        "id": "ZGNmzWUG0ikf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 3 - Training the ANN"
      ],
      "metadata": {
        "id": "ANMU25hn0vIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compiling the ANN"
      ],
      "metadata": {
        "id": "JE68z9qF0xem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ann.compile(...) is a method that configures the model for training. Before a neural network can be trained, it needs to be compiled. This step specifies the optimizer, the loss function, and optionally, the metrics to evaluate during training.\n",
        "# optimizer = 'adam' specifies the 'optimizer' algorithm. The optimizer is like the 'teacher' of the neural network. Its job is to adjust the internal weights of the network during training to minimize the 'loss'. 'Adam' is a popular and very effective optimization algorithm.\n",
        "# loss = 'mean_squared_error' defines the 'loss function'. The loss function is like the 'grading system'. It measures how far off the model's predictions are from the actual values. In regression problems, where we predict continuous values, 'mean_squared_error' (MSE) is a very common choice. It calculates the average of the squared differences between the predicted and actual values. The goal of the optimizer is to make this loss as small as possible.\n",
        "ann.compile(optimizer = 'adam', loss = 'mean_squared_error')"
      ],
      "metadata": {
        "id": "ikgjJX_M0tLu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training the ANN model on the Training set"
      ],
      "metadata": {
        "id": "0hY4UhyX02kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UYBYTbV00NS",
        "outputId": "d59656b6-166f-4e02-fca5-c9d59ff69086"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 175.0605\n",
            "Epoch 2/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 46.0555\n",
            "Epoch 3/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 40.0554\n",
            "Epoch 4/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 34.3572\n",
            "Epoch 5/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 32.3293\n",
            "Epoch 6/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.0965\n",
            "Epoch 7/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.2883\n",
            "Epoch 8/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.8510\n",
            "Epoch 9/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.4445\n",
            "Epoch 10/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.4694\n",
            "Epoch 11/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.0136\n",
            "Epoch 12/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.1030\n",
            "Epoch 13/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 29.8053\n",
            "Epoch 14/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.5309\n",
            "Epoch 15/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.3690\n",
            "Epoch 16/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.6874\n",
            "Epoch 17/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.6185\n",
            "Epoch 18/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.5235\n",
            "Epoch 19/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.9834\n",
            "Epoch 20/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.9096\n",
            "Epoch 21/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.4907\n",
            "Epoch 22/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.9357\n",
            "Epoch 23/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.3591\n",
            "Epoch 24/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.5101\n",
            "Epoch 25/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.5513\n",
            "Epoch 26/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.2926\n",
            "Epoch 27/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.8128\n",
            "Epoch 28/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 26.2553\n",
            "Epoch 29/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 26.5841\n",
            "Epoch 30/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 26.6620\n",
            "Epoch 31/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 27.0292\n",
            "Epoch 32/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 27.5117\n",
            "Epoch 33/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.4547\n",
            "Epoch 34/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.7583\n",
            "Epoch 35/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.3213\n",
            "Epoch 36/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.9640\n",
            "Epoch 37/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.3576\n",
            "Epoch 38/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.7602\n",
            "Epoch 39/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.0483\n",
            "Epoch 40/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.6989\n",
            "Epoch 41/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.5647\n",
            "Epoch 42/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.5177\n",
            "Epoch 43/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.4645\n",
            "Epoch 44/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.0601\n",
            "Epoch 45/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.2284\n",
            "Epoch 46/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.5832\n",
            "Epoch 47/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.0097\n",
            "Epoch 48/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.5387\n",
            "Epoch 49/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.8936\n",
            "Epoch 50/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.1173\n",
            "Epoch 51/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.8619\n",
            "Epoch 52/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.3122\n",
            "Epoch 53/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.5373\n",
            "Epoch 54/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.3728\n",
            "Epoch 55/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 27.5693\n",
            "Epoch 56/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 24.9184\n",
            "Epoch 57/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 24.8464\n",
            "Epoch 58/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.9017\n",
            "Epoch 59/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.2000\n",
            "Epoch 60/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.5472\n",
            "Epoch 61/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.0851\n",
            "Epoch 62/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.7840\n",
            "Epoch 63/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.5955\n",
            "Epoch 64/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.7473\n",
            "Epoch 65/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 26.3249\n",
            "Epoch 66/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.2561\n",
            "Epoch 67/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.6354\n",
            "Epoch 68/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.9874\n",
            "Epoch 69/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.6458\n",
            "Epoch 70/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.3633\n",
            "Epoch 71/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.4870\n",
            "Epoch 72/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.2010\n",
            "Epoch 73/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.4325\n",
            "Epoch 74/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.7623\n",
            "Epoch 75/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.7927\n",
            "Epoch 76/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.3845\n",
            "Epoch 77/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.1542\n",
            "Epoch 78/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.9689\n",
            "Epoch 79/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 26.0703\n",
            "Epoch 80/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 25.3702\n",
            "Epoch 81/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 24.8620\n",
            "Epoch 82/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.8555\n",
            "Epoch 83/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 25.1995\n",
            "Epoch 84/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.7443\n",
            "Epoch 85/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.9338\n",
            "Epoch 86/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 25.2413\n",
            "Epoch 87/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.5641\n",
            "Epoch 88/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.3791\n",
            "Epoch 89/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.2328\n",
            "Epoch 90/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.6849\n",
            "Epoch 91/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.8540\n",
            "Epoch 92/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.0904\n",
            "Epoch 93/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.2095\n",
            "Epoch 94/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.3600\n",
            "Epoch 95/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.4316\n",
            "Epoch 96/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.9070\n",
            "Epoch 97/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.9915\n",
            "Epoch 98/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.1362\n",
            "Epoch 99/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.1273\n",
            "Epoch 100/100\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.5198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ccddfbdeff0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Predicting the results of the Test set"
      ],
      "metadata": {
        "id": "1FaxlW-u1IqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's pick the first 5 examples from our test set\n",
        "num_examples = 5\n",
        "X_test_sample = X_test[:num_examples]\n",
        "y_test_sample = y_test[:num_examples]\n",
        "\n",
        "# Ask our smart computer to make predictions for these examples\n",
        "y_pred_sample = ann.predict(X_test_sample)\n",
        "\n",
        "# Now let's compare the guesses to what actually happened!\n",
        "for i in range(num_examples):\n",
        "    print(f\"Situation {i+1}:\")\n",
        "    print(f\"  The power plant actually made: {y_test_sample[i]:.2f} units of electricity.\")\n",
        "    print(f\"  Our computer guessed it would make: {y_pred_sample[i][0]:.2f} units of electricity.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G_sd__91M93",
        "outputId": "04437820-5e79-4043-f74e-c60c67c840b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Situation 1:\n",
            "  The power plant actually made: 431.23 units of electricity.\n",
            "  Our computer guessed it would make: 432.05 units of electricity.\n",
            "Situation 2:\n",
            "  The power plant actually made: 460.01 units of electricity.\n",
            "  Our computer guessed it would make: 460.73 units of electricity.\n",
            "Situation 3:\n",
            "  The power plant actually made: 461.14 units of electricity.\n",
            "  Our computer guessed it would make: 466.92 units of electricity.\n",
            "Situation 4:\n",
            "  The power plant actually made: 445.90 units of electricity.\n",
            "  Our computer guessed it would make: 446.96 units of electricity.\n",
            "Situation 5:\n",
            "  The power plant actually made: 451.29 units of electricity.\n",
            "  Our computer guessed it would make: 457.06 units of electricity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r43YRL-72Tka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
